{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction:\nIn this notebook we'll test out Tensorflow Decsion Trees.","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade tensorflow_decision_forests","metadata":{"execution":{"iopub.status.busy":"2023-02-16T05:57:39.258452Z","iopub.execute_input":"2023-02-16T05:57:39.259456Z","iopub.status.idle":"2023-02-16T05:58:53.615606Z","shell.execute_reply.started":"2023-02-16T05:57:39.258841Z","shell.execute_reply":"2023-02-16T05:58:53.614846Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow_decision_forests in /opt/conda/lib/python3.7/site-packages (0.2.0)\nCollecting tensorflow_decision_forests\n  Downloading tensorflow_decision_forests-1.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from tensorflow_decision_forests) (1.21.6)\nCollecting tensorflow~=2.11.0\n  Downloading tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from tensorflow_decision_forests) (1.3.5)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from tensorflow_decision_forests) (1.15.0)\nCollecting wurlitzer\n  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from tensorflow_decision_forests) (0.37.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from tensorflow_decision_forests) (0.15.0)\nCollecting tensorflow-io-gcs-filesystem>=0.23.1\n  Downloading tensorflow_io_gcs_filesystem-0.30.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (3.19.4)\nCollecting absl-py\n  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting flatbuffers>=2.0\n  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (0.4.0)\nCollecting tensorflow-estimator<2.12,>=2.11.0\n  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tensorboard<2.12,>=2.11\n  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (1.1.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (1.6.3)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (4.1.1)\nCollecting keras<2.12,>=2.11.0\n  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (59.8.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (1.12.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (1.47.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (23.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (3.8.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (3.3.0)\nCollecting libclang>=13.0.0\n  Downloading libclang-15.0.6.1-py2.py3-none-manylinux2010_x86_64.whl (21.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->tensorflow_decision_forests) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->tensorflow_decision_forests) (2022.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (1.35.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2.28.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.4.6)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (3.3.7)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2.2.2)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (1.8.1)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (4.2.4)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (4.8)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.2.7)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (1.3.1)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (6.0.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (3.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2.1.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (3.8.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (3.2.0)\nInstalling collected packages: libclang, flatbuffers, wurlitzer, tensorflow-io-gcs-filesystem, tensorflow-estimator, keras, absl-py, tensorboard, tensorflow, tensorflow_decision_forests\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 1.12\n    Uninstalling flatbuffers-1.12:\n      Successfully uninstalled flatbuffers-1.12\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.6.0\n    Uninstalling tensorflow-estimator-2.6.0:\n      Successfully uninstalled tensorflow-estimator-2.6.0\n  Attempting uninstall: keras\n    Found existing installation: keras 2.6.0\n    Uninstalling keras-2.6.0:\n      Successfully uninstalled keras-2.6.0\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 0.15.0\n    Uninstalling absl-py-0.15.0:\n      Successfully uninstalled absl-py-0.15.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.6.0\n    Uninstalling tensorboard-2.6.0:\n      Successfully uninstalled tensorboard-2.6.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.6.4\n    Uninstalling tensorflow-2.6.4:\n      Successfully uninstalled tensorflow-2.6.4\n  Attempting uninstall: tensorflow_decision_forests\n    Found existing installation: tensorflow-decision-forests 0.2.0\n    Uninstalling tensorflow-decision-forests-0.2.0:\n      Successfully uninstalled tensorflow-decision-forests-0.2.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntfx-bsl 1.9.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.52.0 which is incompatible.\ntfx-bsl 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.11.0 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 2.11.0 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, but you have tensorflow-io-gcs-filesystem 0.30.0 which is incompatible.\nortools 9.5.2237 requires protobuf>=4.21.5, but you have protobuf 3.19.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed absl-py-1.4.0 flatbuffers-23.1.21 keras-2.11.0 libclang-15.0.6.1 tensorboard-2.11.2 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.30.0 tensorflow_decision_forests-1.2.0 wurlitzer-3.0.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nfrom pathlib import Path\n\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom IPython.display import display\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\nfrom category_encoders import LeaveOneOutEncoder\nimport optuna\nfrom sklearn.preprocessing import StandardScaler\n\nimport tensorflow_decision_forests as tfdf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-16T05:58:57.366199Z","iopub.execute_input":"2023-02-16T05:58:57.367642Z","iopub.status.idle":"2023-02-16T05:59:02.147581Z","shell.execute_reply.started":"2023-02-16T05:58:57.367578Z","shell.execute_reply":"2023-02-16T05:59:02.146796Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2023-02-16 05:58:58.433918: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-02-16 05:58:58.585346: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n2023-02-16 05:58:58.585386: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2023-02-16 05:58:59.587779: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n2023-02-16 05:58:59.587915: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n2023-02-16 05:58:59.587925: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","output_type":"stream"}]},{"cell_type":"code","source":"from warnings import filterwarnings\nfilterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-02-16T05:59:22.354297Z","iopub.execute_input":"2023-02-16T05:59:22.354713Z","iopub.status.idle":"2023-02-16T05:59:22.359001Z","shell.execute_reply.started":"2023-02-16T05:59:22.354678Z","shell.execute_reply":"2023-02-16T05:59:22.358257Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"BASE_PATH = Path(\"/kaggle/input/playground-series-s3e7\")\n\ntrain = pd.read_csv(BASE_PATH / \"train.csv\").drop(columns=\"id\")\ntrain[\"is_original\"] = 0\ntest = pd.read_csv(BASE_PATH / \"test.csv\")\n# we'll need the test ids to make the submission file\ntest_idx = test.id\ntest = test.drop(columns=\"id\")\ntest[\"is_original\"] = 0\n\noriginal = pd.read_csv(\"/kaggle/input/reservation-cancellation-prediction/train__dataset.csv\")\noriginal[\"is_original\"] =  1","metadata":{"execution":{"iopub.status.busy":"2023-02-16T05:59:05.673040Z","iopub.execute_input":"2023-02-16T05:59:05.673509Z","iopub.status.idle":"2023-02-16T05:59:05.846524Z","shell.execute_reply.started":"2023-02-16T05:59:05.673468Z","shell.execute_reply":"2023-02-16T05:59:05.845100Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"all_datasets = {\"train\": train,\n               \"test\": test,\n               \"original\": original}","metadata":{"execution":{"iopub.status.busy":"2023-02-16T05:59:06.111192Z","iopub.execute_input":"2023-02-16T05:59:06.111560Z","iopub.status.idle":"2023-02-16T05:59:06.117402Z","shell.execute_reply.started":"2023-02-16T05:59:06.111531Z","shell.execute_reply":"2023-02-16T05:59:06.116242Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Preliminary Data Analysis","metadata":{"execution":{"iopub.status.busy":"2023-02-14T08:11:55.064506Z","iopub.execute_input":"2023-02-14T08:11:55.064955Z","iopub.status.idle":"2023-02-14T08:11:55.070876Z","shell.execute_reply.started":"2023-02-14T08:11:55.06492Z","shell.execute_reply":"2023-02-14T08:11:55.069408Z"}}},{"cell_type":"markdown","source":"# Removing anomalies.\nHuge thanks to https://www.kaggle.com/competitions/playground-series-s3e7/discussion/386655","metadata":{}},{"cell_type":"code","source":"train['arrival_year_month'] = pd.to_datetime(train['arrival_year'].astype(str)\n                                            +train['arrival_month'].astype(str), format='%Y%m')\ntest['arrival_year_month'] = pd.to_datetime(test['arrival_year'].astype(str)\n                                            +test['arrival_month'].astype(str), format='%Y%m')\noriginal[\"arrival_year_month\"] = pd.to_datetime(original[\"arrival_year\"].astype(str)\n                                            +original[\"arrival_month\"].astype(str), format=\"%Y%m\")\n\ntrain.loc[train.arrival_date > train.arrival_year_month.dt.days_in_month, 'arrival_date'] = train.arrival_year_month.dt.days_in_month\ntest.loc[test.arrival_date > test.arrival_year_month.dt.days_in_month, 'arrival_date'] = test.arrival_year_month.dt.days_in_month\noriginal.loc[original.arrival_date > original.arrival_year_month.dt.days_in_month, 'arrival_date'] = original.arrival_year_month.dt.days_in_month\n\ntrain.drop(columns='arrival_year_month', inplace=True)\ntest.drop(columns='arrival_year_month', inplace=True)\noriginal.drop(columns=\"arrival_year_month\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T05:59:09.559672Z","iopub.execute_input":"2023-02-16T05:59:09.561182Z","iopub.status.idle":"2023-02-16T05:59:09.711190Z","shell.execute_reply.started":"2023-02-16T05:59:09.561130Z","shell.execute_reply":"2023-02-16T05:59:09.709325Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"combined_df = pd.concat([train, original], axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T05:59:11.557921Z","iopub.execute_input":"2023-02-16T05:59:11.558318Z","iopub.status.idle":"2023-02-16T05:59:11.570600Z","shell.execute_reply.started":"2023-02-16T05:59:11.558286Z","shell.execute_reply":"2023-02-16T05:59:11.569014Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# train_c_df = train_test_split()","metadata":{"execution":{"iopub.status.busy":"2023-02-16T05:59:13.917423Z","iopub.execute_input":"2023-02-16T05:59:13.917818Z","iopub.status.idle":"2023-02-16T05:59:13.922852Z","shell.execute_reply.started":"2023-02-16T05:59:13.917784Z","shell.execute_reply":"2023-02-16T05:59:13.921784Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"combined_ds = tfdf.keras.pd_dataframe_to_tf_dataset(combined_df, label=\"booking_status\")","metadata":{"execution":{"iopub.status.busy":"2023-02-16T05:59:14.238427Z","iopub.execute_input":"2023-02-16T05:59:14.238766Z","iopub.status.idle":"2023-02-16T05:59:14.308550Z","shell.execute_reply.started":"2023-02-16T05:59:14.238738Z","shell.execute_reply":"2023-02-16T05:59:14.305640Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2023-02-16 05:59:14.256542: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n2023-02-16 05:59:14.256607: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n2023-02-16 05:59:14.256638: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (9b03a22c60ff): /proc/driver/nvidia/version does not exist\n2023-02-16 05:59:14.257036: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T06:19:46.471011Z","iopub.execute_input":"2023-02-16T06:19:46.471386Z","iopub.status.idle":"2023-02-16T06:19:46.500192Z","shell.execute_reply.started":"2023-02-16T06:19:46.471358Z","shell.execute_reply":"2023-02-16T06:19:46.499160Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# # tuner = tfdf.tuner.RandomSearch()\n# model = tfdf.keras.GradientBoostedTreesModel(verbose=0)\n# model.compile(metrics=[])\n# model.fit(combined_ds)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T05:59:33.079253Z","iopub.execute_input":"2023-02-16T05:59:33.079585Z","iopub.status.idle":"2023-02-16T06:00:19.362896Z","shell.execute_reply.started":"2023-02-16T05:59:33.079560Z","shell.execute_reply":"2023-02-16T06:00:19.361619Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"2023-02-16 05:59:38.947495: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1790] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n2023-02-16 05:59:38.947706: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1800] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n2023-02-16 05:59:38.947734: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1814] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n[INFO 2023-02-16T06:00:04.273370795+00:00 kernel.cc:1214] Loading model from path /tmp/tmpiy3gjau3/model/ with prefix 3b9475149f35445b\n[INFO 2023-02-16T06:00:04.301515588+00:00 abstract_model.cc:1311] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n[INFO 2023-02-16T06:00:04.301578047+00:00 kernel.cc:1046] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7faf93c9fb90> and will run it as-is.\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\nCause: could not get source code\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7faf95a08a90>"},"metadata":{}}]},{"cell_type":"code","source":"# model.predict(test_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting up cross validation","metadata":{}},{"cell_type":"code","source":"def cross_validate(X, y, X_org, y_org):\n    N_FOLDS = 5\n    \n    skf = StratifiedKFold(n_splits=N_FOLDS, random_state=1337, shuffle=True)\n    cv_scores = np.zeros(N_FOLDS)\n    \n    for fold_id, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n        \n        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n        # combining with original\n        X_tr = pd.concat([X_tr, X_org], axis=0)\n        y_tr = pd.concat([y_tr, y_org], axis=0)\n\n        X_tr = pd.concat([X_tr, y_tr], axis=1)\n        \n        \n        X_tr_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_tr, label=\"booking_status\")\n        X_val_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_val)\n        \n        model = tfdf.keras.GradientBoostedTreesModel(verbose=0)\n        model.fit(combined_ds)\n        \n        y_pred = model.predict(X_val_ds)[:, 0]\n        \n        auc = roc_auc_score(y_val, y_pred)\n        \n        print(f\"Fold: {fold_id} \\t | \\t auc: {auc}\")\n        \n        cv_scores[fold_id] = auc\n    \n    avg_auc = np.mean(cv_scores)\n    print(f\"AVG AUC: {avg_auc}\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X = train.drop(columns=\"booking_status\")\n# y = train.booking_status\n# X_original = original.drop(columns=\"booking_status\")\n# y_original = original.booking_status","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cross_validate(X, y, X_original, y_original)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SHOCKING RESULTS | AVG AUC: 0.9189137654978039","metadata":{}},{"cell_type":"markdown","source":"# NEXT UP:\nCurrently TFDF is treating all features as numerical, but we clearly know there are many categorical, so let's set those categorical as categorical and see how it fares.","metadata":{}},{"cell_type":"markdown","source":"## Checking for categorical values","metadata":{}},{"cell_type":"code","source":"# pd.concat([train.dtypes.rename(\"Data Type\")] + \\\n#           [dataset.nunique().rename(f\"{dataset_name} UniqueValues\") for dataset_name, dataset in all_datasets.items()],\n#           axis=1).sort_values(by=\"train UniqueValues\")","metadata":{"execution":{"iopub.status.busy":"2023-02-16T06:00:55.306859Z","iopub.execute_input":"2023-02-16T06:00:55.307255Z","iopub.status.idle":"2023-02-16T06:00:55.349816Z","shell.execute_reply.started":"2023-02-16T06:00:55.307223Z","shell.execute_reply":"2023-02-16T06:00:55.348457Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                     Data Type  train UniqueValues  \\\nis_original                              int64                   1   \nrepeated_guest                           int64                   2   \nbooking_status                           int64                   2   \nrequired_car_parking_space               int64                   2   \narrival_year                             int64                   2   \ntype_of_meal_plan                        int64                   4   \nmarket_segment_type                      int64                   5   \nno_of_adults                             int64                   5   \nno_of_children                           int64                   6   \nno_of_special_requests                   int64                   6   \nroom_type_reserved                       int64                   7   \nno_of_weekend_nights                     int64                   8   \nno_of_previous_cancellations             int64                  10   \narrival_month                            int64                  12   \nno_of_week_nights                        int64                  18   \narrival_date                             int64                  31   \nno_of_previous_bookings_not_canceled     int64                  42   \nlead_time                                int64                 338   \navg_price_per_room                     float64                2286   \n\n                                      test UniqueValues  original UniqueValues  \nis_original                                         1.0                      1  \nrepeated_guest                                      2.0                      2  \nbooking_status                                      NaN                      2  \nrequired_car_parking_space                          2.0                      2  \narrival_year                                        2.0                      2  \ntype_of_meal_plan                                   4.0                      4  \nmarket_segment_type                                 5.0                      5  \nno_of_adults                                        5.0                      5  \nno_of_children                                      6.0                      5  \nno_of_special_requests                              6.0                      6  \nroom_type_reserved                                  7.0                      7  \nno_of_weekend_nights                                7.0                      8  \nno_of_previous_cancellations                        9.0                      9  \narrival_month                                      12.0                     12  \nno_of_week_nights                                  18.0                     18  \narrival_date                                       31.0                     31  \nno_of_previous_bookings_not_canceled               47.0                     47  \nlead_time                                         334.0                    341  \navg_price_per_room                               2058.0                   2722  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data Type</th>\n      <th>train UniqueValues</th>\n      <th>test UniqueValues</th>\n      <th>original UniqueValues</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>is_original</th>\n      <td>int64</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>repeated_guest</th>\n      <td>int64</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>booking_status</th>\n      <td>int64</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>required_car_parking_space</th>\n      <td>int64</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>arrival_year</th>\n      <td>int64</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>type_of_meal_plan</th>\n      <td>int64</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>market_segment_type</th>\n      <td>int64</td>\n      <td>5</td>\n      <td>5.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>no_of_adults</th>\n      <td>int64</td>\n      <td>5</td>\n      <td>5.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>no_of_children</th>\n      <td>int64</td>\n      <td>6</td>\n      <td>6.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>no_of_special_requests</th>\n      <td>int64</td>\n      <td>6</td>\n      <td>6.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>room_type_reserved</th>\n      <td>int64</td>\n      <td>7</td>\n      <td>7.0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>no_of_weekend_nights</th>\n      <td>int64</td>\n      <td>8</td>\n      <td>7.0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>no_of_previous_cancellations</th>\n      <td>int64</td>\n      <td>10</td>\n      <td>9.0</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>arrival_month</th>\n      <td>int64</td>\n      <td>12</td>\n      <td>12.0</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>no_of_week_nights</th>\n      <td>int64</td>\n      <td>18</td>\n      <td>18.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>arrival_date</th>\n      <td>int64</td>\n      <td>31</td>\n      <td>31.0</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>no_of_previous_bookings_not_canceled</th>\n      <td>int64</td>\n      <td>42</td>\n      <td>47.0</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>lead_time</th>\n      <td>int64</td>\n      <td>338</td>\n      <td>334.0</td>\n      <td>341</td>\n    </tr>\n    <tr>\n      <th>avg_price_per_room</th>\n      <td>float64</td>\n      <td>2286</td>\n      <td>2058.0</td>\n      <td>2722</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"cat_features = [col for col in train.columns if train[col].nunique() <= 31]\n\n# removinng booking status and is_original\ncat_features = cat_features[:-2]\ncat_features.append(\"is_original\")","metadata":{"execution":{"iopub.status.busy":"2023-02-16T06:01:07.896298Z","iopub.execute_input":"2023-02-16T06:01:07.896642Z","iopub.status.idle":"2023-02-16T06:01:07.908372Z","shell.execute_reply.started":"2023-02-16T06:01:07.896614Z","shell.execute_reply":"2023-02-16T06:01:07.907216Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"len(cat_features)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T06:01:10.023238Z","iopub.execute_input":"2023-02-16T06:01:10.023577Z","iopub.status.idle":"2023-02-16T06:01:10.030031Z","shell.execute_reply.started":"2023-02-16T06:01:10.023551Z","shell.execute_reply":"2023-02-16T06:01:10.029128Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"15"},"metadata":{}}]},{"cell_type":"markdown","source":"## Defining feature semantics","metadata":{}},{"cell_type":"code","source":"tf_cat_features = []\nfor feature in cat_features:\n    tf_cat_features.append(tfdf.keras.FeatureUsage(name=str(feature), semantic=tfdf.keras.FeatureSemantic.CATEGORICAL))\n\n# tf_cat_features","metadata":{"execution":{"iopub.status.busy":"2023-02-16T06:01:12.445357Z","iopub.execute_input":"2023-02-16T06:01:12.445906Z","iopub.status.idle":"2023-02-16T06:01:12.450770Z","shell.execute_reply.started":"2023-02-16T06:01:12.445878Z","shell.execute_reply":"2023-02-16T06:01:12.449872Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"feat_1 = tfdf.keras.FeatureUsage(name=\"lead_time\", semantic=tfdf.keras.FeatureSemantic.NUMERICAL)\nfeat_2 = tfdf.keras.FeatureUsage(name=\"avg_price_per_room\", semantic=tfdf.keras.FeatureSemantic.NUMERICAL)\nfeat_3 = tfdf.keras.FeatureUsage(name=\"no_of_previous_bookings_not_canceled\", semantic=tfdf.keras.FeatureSemantic.NUMERICAL)\n\ntf_num_features = [feat_1, feat_2, feat_3]\n\nall_features = tf_cat_features + tf_num_features","metadata":{"execution":{"iopub.status.busy":"2023-02-16T06:01:12.765114Z","iopub.execute_input":"2023-02-16T06:01:12.765492Z","iopub.status.idle":"2023-02-16T06:01:12.771560Z","shell.execute_reply.started":"2023-02-16T06:01:12.765465Z","shell.execute_reply":"2023-02-16T06:01:12.770428Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"len(all_features)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T06:01:14.954792Z","iopub.execute_input":"2023-02-16T06:01:14.955183Z","iopub.status.idle":"2023-02-16T06:01:14.961837Z","shell.execute_reply.started":"2023-02-16T06:01:14.955155Z","shell.execute_reply":"2023-02-16T06:01:14.960493Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"18"},"metadata":{}}]},{"cell_type":"code","source":"set(X.columns) - set(cat_features)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T06:01:25.038687Z","iopub.execute_input":"2023-02-16T06:01:25.039050Z","iopub.status.idle":"2023-02-16T06:01:25.333128Z","shell.execute_reply.started":"2023-02-16T06:01:25.039022Z","shell.execute_reply":"2023-02-16T06:01:25.331888Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":18,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1520444118.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"],"ename":"NameError","evalue":"name 'X' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# def cross_validate_with_features(X, y, X_org, y_org, all_features):\n#     N_FOLDS = 5\n    \n#     skf = StratifiedKFold(n_splits=N_FOLDS, random_state=1337, shuffle=True)\n#     cv_scores = np.zeros(N_FOLDS)\n#     all_test_preds  = []\n    \n#     for fold_id, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n        \n#         X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n#         y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n#         # combining with original\n#         X_tr = pd.concat([X_tr, X_org], axis=0)\n#         y_tr = pd.concat([y_tr, y_org], axis=0)\n\n#         X_tr = pd.concat([X_tr, y_tr], axis=1)\n        \n        \n#         X_tr_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_tr, label=\"booking_status\")\n#         X_val_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_val)\n        \n#         model = tfdf.keras.GradientBoostedTreesModel(verbose=0, features=all_features, exclude_non_specified_features=True)\n#         model.fit(combined_ds)\n        \n#         y_pred = model.predict(X_val_ds)[:, 0]\n        \n#         auc = roc_auc_score(y_val, y_pred)\n        \n#         print(f\"Fold: {fold_id} \\t | \\t auc: {auc}\")\n        \n#         cv_scores[fold_id] = auc\n#         all_test_preds.append(model.predict(test_ds)[:, 0])\n\n    \n#     avg_auc = np.mean(cv_scores)\n#     print(f\"AVG AUC: {avg_auc}\")\n#     return all_test_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final_test_preds = cross_validate_with_features(X, y, X_original, y_original, all_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EVEN MORE SHCOKING RESULTS | AVG AUC: 0.930750011417936","metadata":{}},{"cell_type":"markdown","source":"# Let's make the submission","metadata":{"execution":{"iopub.status.busy":"2023-02-15T18:19:49.767781Z","iopub.execute_input":"2023-02-15T18:19:49.768327Z","iopub.status.idle":"2023-02-15T18:19:49.773716Z","shell.execute_reply.started":"2023-02-15T18:19:49.768281Z","shell.execute_reply":"2023-02-15T18:19:49.772450Z"}}},{"cell_type":"code","source":"# y_preds_final = np.array(final_test_preds).mean(axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = pd.DataFrame({\"id\": test_idx, \"booking_status\": y_preds_final})\n# submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Next Up: Let's use predefined hyperparameters templates","metadata":{}},{"cell_type":"code","source":"# def cross_validate_with_features_and_hp_template(X, y, X_org, y_org, all_features):\n#     N_FOLDS = 5\n    \n#     skf = StratifiedKFold(n_splits=N_FOLDS, random_state=1337, shuffle=True)\n#     cv_scores = np.zeros(N_FOLDS)\n    \n#     for fold_id, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n        \n#         X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n#         y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n#         # combining with original\n#         X_tr = pd.concat([X_tr, X_org], axis=0)\n#         y_tr = pd.concat([y_tr, y_org], axis=0)\n\n#         X_tr = pd.concat([X_tr, y_tr], axis=1)\n        \n        \n#         X_tr_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_tr, label=\"booking_status\")\n#         X_val_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_val)\n        \n#         model = tfdf.keras.GradientBoostedTreesModel(verbose=0, features=all_features, exclude_non_specified_features=True,\n#                                                     hyperparameter_template=\"benchmark_rank1\")\n#         model.fit(combined_ds)\n        \n#         y_pred = model.predict(X_val_ds)[:, 0]\n        \n#         auc = roc_auc_score(y_val, y_pred)\n        \n#         print(f\"Fold: {fold_id} \\t | \\t auc: {auc}\")\n        \n#         cv_scores[fold_id] = auc\n    \n#     avg_auc = np.mean(cv_scores)\n#     print(f\"AVG AUC: {avg_auc}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cross_validate_with_features_and_hp_template(X, y, X_original, y_original, all_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RESULTS - a bit worse | AVG AUC: 0.9210854344787212","metadata":{}},{"cell_type":"markdown","source":"# NEXT UP: Let's tune hps automatically","metadata":{"execution":{"iopub.status.busy":"2023-02-15T17:32:11.919726Z","iopub.execute_input":"2023-02-15T17:32:11.920872Z","iopub.status.idle":"2023-02-15T17:32:11.925654Z","shell.execute_reply.started":"2023-02-15T17:32:11.920820Z","shell.execute_reply":"2023-02-15T17:32:11.924462Z"}}},{"cell_type":"code","source":"tuner = tfdf.tuner.RandomSearch(num_trials=50, use_predefined_hps=True)\ntuned_model = tfdf.keras.GradientBoostedTreesModel(verbose=2, tuner=tuner, features=all_features, exclude_non_specified_features=True)\ntuned_model.fit(combined_ds)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T06:01:52.275345Z","iopub.execute_input":"2023-02-16T06:01:52.275701Z","iopub.status.idle":"2023-02-16T06:17:31.132180Z","shell.execute_reply.started":"2023-02-16T06:01:52.275672Z","shell.execute_reply":"2023-02-16T06:17:31.131043Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Use 4 thread(s) for training\nUse /tmp/tmp85tojlvh as temporary training directory\nReading training dataset...\nTraining tensor examples:\nFeatures: {'no_of_adults': <tf.Tensor 'data_7:0' shape=(None,) dtype=int64>, 'no_of_children': <tf.Tensor 'data_8:0' shape=(None,) dtype=int64>, 'no_of_weekend_nights': <tf.Tensor 'data_13:0' shape=(None,) dtype=int64>, 'no_of_week_nights': <tf.Tensor 'data_12:0' shape=(None,) dtype=int64>, 'type_of_meal_plan': <tf.Tensor 'data_17:0' shape=(None,) dtype=int64>, 'required_car_parking_space': <tf.Tensor 'data_15:0' shape=(None,) dtype=int64>, 'room_type_reserved': <tf.Tensor 'data_16:0' shape=(None,) dtype=int64>, 'lead_time': <tf.Tensor 'data_5:0' shape=(None,) dtype=int64>, 'arrival_year': <tf.Tensor 'data_2:0' shape=(None,) dtype=int64>, 'arrival_month': <tf.Tensor 'data_1:0' shape=(None,) dtype=int64>, 'arrival_date': <tf.Tensor 'data:0' shape=(None,) dtype=int64>, 'market_segment_type': <tf.Tensor 'data_6:0' shape=(None,) dtype=int64>, 'repeated_guest': <tf.Tensor 'data_14:0' shape=(None,) dtype=int64>, 'no_of_previous_cancellations': <tf.Tensor 'data_10:0' shape=(None,) dtype=int64>, 'no_of_previous_bookings_not_canceled': <tf.Tensor 'data_9:0' shape=(None,) dtype=int64>, 'avg_price_per_room': <tf.Tensor 'data_3:0' shape=(None,) dtype=float64>, 'no_of_special_requests': <tf.Tensor 'data_11:0' shape=(None,) dtype=int64>, 'is_original': <tf.Tensor 'data_4:0' shape=(None,) dtype=int64>}\nLabel: Tensor(\"data_18:0\", shape=(None,), dtype=int64)\nWeights: None\nNormalized tensor features:\n {'no_of_adults': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'add:0' shape=(None,) dtype=int32>), 'no_of_children': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'add_1:0' shape=(None,) dtype=int32>), 'no_of_weekend_nights': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'add_2:0' shape=(None,) dtype=int32>), 'no_of_week_nights': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'add_3:0' shape=(None,) dtype=int32>), 'type_of_meal_plan': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'add_4:0' shape=(None,) dtype=int32>), 'required_car_parking_space': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'add_5:0' shape=(None,) dtype=int32>), 'room_type_reserved': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'add_6:0' shape=(None,) dtype=int32>), 'lead_time': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_7:0' shape=(None,) dtype=float32>), 'arrival_year': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'add_7:0' shape=(None,) dtype=int32>), 'arrival_month': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'add_8:0' shape=(None,) dtype=int32>), 'arrival_date': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'add_9:0' shape=(None,) dtype=int32>), 'market_segment_type': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'add_10:0' shape=(None,) dtype=int32>), 'repeated_guest': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'add_11:0' shape=(None,) dtype=int32>), 'no_of_previous_cancellations': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'add_12:0' shape=(None,) dtype=int32>), 'no_of_previous_bookings_not_canceled': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_14:0' shape=(None,) dtype=float32>), 'avg_price_per_room': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_15:0' shape=(None,) dtype=float32>), 'no_of_special_requests': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'add_13:0' shape=(None,) dtype=int32>), 'is_original': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'add_14:0' shape=(None,) dtype=int32>)}\nTraining dataset read in 0:00:00.733689. Found 60237 examples.\nTraining model...\nStandard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n","output_type":"stream"},{"name":"stderr","text":"[INFO 2023-02-16T06:01:53.050453918+00:00 kernel.cc:756] Start Yggdrasil model training\n[INFO 2023-02-16T06:01:53.050575449+00:00 kernel.cc:757] Collect training examples\n[INFO 2023-02-16T06:01:53.052324288+00:00 kernel.cc:388] Number of batches: 61\n[INFO 2023-02-16T06:01:53.052345438+00:00 kernel.cc:389] Number of examples: 60237\n[INFO 2023-02-16T06:01:53.063126123+00:00 kernel.cc:774] Training dataset:\nNumber of records: 60237\nNumber of columns: 19\n\nNumber of columns by type:\n\tCATEGORICAL: 16 (84.2105%)\n\tNUMERICAL: 3 (15.7895%)\n\nColumns:\n\nCATEGORICAL: 16 (84.2105%)\n\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\t1: \"arrival_date\" CATEGORICAL integerized vocab-size:33 no-ood-item\n\t2: \"arrival_month\" CATEGORICAL integerized vocab-size:14 no-ood-item\n\t3: \"arrival_year\" CATEGORICAL integerized vocab-size:2020 no-ood-item\n\t5: \"is_original\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\t7: \"market_segment_type\" CATEGORICAL integerized vocab-size:6 no-ood-item\n\t8: \"no_of_adults\" CATEGORICAL integerized vocab-size:6 no-ood-item\n\t9: \"no_of_children\" CATEGORICAL integerized vocab-size:11 no-ood-item\n\t11: \"no_of_previous_cancellations\" CATEGORICAL integerized vocab-size:15 no-ood-item\n\t12: \"no_of_special_requests\" CATEGORICAL integerized vocab-size:7 no-ood-item\n\t13: \"no_of_week_nights\" CATEGORICAL integerized vocab-size:19 no-ood-item\n\t14: \"no_of_weekend_nights\" CATEGORICAL integerized vocab-size:9 no-ood-item\n\t15: \"repeated_guest\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\t16: \"required_car_parking_space\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\t17: \"room_type_reserved\" CATEGORICAL integerized vocab-size:8 no-ood-item\n\t18: \"type_of_meal_plan\" CATEGORICAL integerized vocab-size:5 no-ood-item\n\nNUMERICAL: 3 (15.7895%)\n\t4: \"avg_price_per_room\" NUMERICAL mean:104.239 min:0 max:540 sd:36.6486\n\t6: \"lead_time\" NUMERICAL mean:98.3146 min:0 max:443 sd:83.2102\n\t10: \"no_of_previous_bookings_not_canceled\" NUMERICAL mean:0.168435 min:0 max:58 sd:1.72673\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\n[INFO 2023-02-16T06:01:53.063191333+00:00 kernel.cc:790] Configure learner\n2023-02-16 06:01:53.063532: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1790] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n2023-02-16 06:01:53.063581: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1800] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n2023-02-16 06:01:53.063595: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1814] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n[INFO 2023-02-16T06:01:53.063680743+00:00 kernel.cc:804] Training config:\nlearner: \"HYPERPARAMETER_OPTIMIZER\"\nfeatures: \"^arrival_date$\"\nfeatures: \"^arrival_month$\"\nfeatures: \"^arrival_year$\"\nfeatures: \"^avg_price_per_room$\"\nfeatures: \"^is_original$\"\nfeatures: \"^lead_time$\"\nfeatures: \"^market_segment_type$\"\nfeatures: \"^no_of_adults$\"\nfeatures: \"^no_of_children$\"\nfeatures: \"^no_of_previous_bookings_not_canceled$\"\nfeatures: \"^no_of_previous_cancellations$\"\nfeatures: \"^no_of_special_requests$\"\nfeatures: \"^no_of_week_nights$\"\nfeatures: \"^no_of_weekend_nights$\"\nfeatures: \"^repeated_guest$\"\nfeatures: \"^required_car_parking_space$\"\nfeatures: \"^room_type_reserved$\"\nfeatures: \"^type_of_meal_plan$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nmetadata {\n  framework: \"TF Keras\"\n}\n[yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.hyperparameters_optimizer_config] {\n  base_learner {\n    learner: \"GRADIENT_BOOSTED_TREES\"\n    features: \"^arrival_date$\"\n    features: \"^arrival_month$\"\n    features: \"^arrival_year$\"\n    features: \"^avg_price_per_room$\"\n    features: \"^is_original$\"\n    features: \"^lead_time$\"\n    features: \"^market_segment_type$\"\n    features: \"^no_of_adults$\"\n    features: \"^no_of_children$\"\n    features: \"^no_of_previous_bookings_not_canceled$\"\n    features: \"^no_of_previous_cancellations$\"\n    features: \"^no_of_special_requests$\"\n    features: \"^no_of_week_nights$\"\n    features: \"^no_of_weekend_nights$\"\n    features: \"^repeated_guest$\"\n    features: \"^required_car_parking_space$\"\n    features: \"^room_type_reserved$\"\n    features: \"^type_of_meal_plan$\"\n    label: \"^__LABEL$\"\n    task: CLASSIFICATION\n    random_seed: 123456\n    pure_serving_model: false\n    [yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n      num_trees: 300\n      decision_tree {\n        max_depth: 6\n        min_examples: 5\n        in_split_min_examples_check: true\n        keep_non_leaf_label_distribution: true\n        num_candidate_attributes: -1\n        missing_value_policy: GLOBAL_IMPUTATION\n        allow_na_conditions: false\n        categorical_set_greedy_forward {\n          sampling: 0.1\n          max_num_items: -1\n          min_item_frequency: 1\n        }\n        growing_strategy_local {\n        }\n        categorical {\n          cart {\n          }\n        }\n        axis_aligned_split {\n        }\n        internal {\n          sorting_strategy: PRESORTED\n        }\n        uplift {\n          min_examples_in_treatment: 5\n          split_score: KULLBACK_LEIBLER\n        }\n      }\n      shrinkage: 0.1\n      loss: DEFAULT\n      validation_set_ratio: 0.1\n      validation_interval_in_trees: 1\n      early_stopping: VALIDATION_LOSS_INCREASE\n      early_stopping_num_trees_look_ahead: 30\n      l2_regularization: 0\n      lambda_loss: 1\n      mart {\n      }\n      adapt_subsample_for_maximum_training_duration: false\n      l1_regularization: 0\n      use_hessian_gain: false\n      l2_regularization_categorical: 1\n      stochastic_gradient_boosting {\n        ratio: 1\n      }\n      apply_link_function: true\n      compute_permutation_variable_importance: false\n      binary_focal_loss_options {\n        misprediction_exponent: 2\n        positive_sample_coefficient: 0.5\n      }\n      early_stopping_initial_iteration: 10\n    }\n  }\n  optimizer {\n    optimizer_key: \"RANDOM\"\n    [yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.random] {\n      num_trials: 50\n    }\n  }\n  base_learner_deployment {\n    num_threads: 1\n  }\n  predefined_search_space {\n  }\n}\n\n[INFO 2023-02-16T06:01:53.064015233+00:00 kernel.cc:807] Deployment config:\ncache_path: \"/tmp/tmp85tojlvh/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\n[INFO 2023-02-16T06:01:53.064227622+00:00 kernel.cc:868] Train model\n[INFO 2023-02-16T06:03:35.268594278+00:00 early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.722788\n[INFO 2023-02-16T06:09:16.588522797+00:00 early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.718314\n[INFO 2023-02-16T06:12:07.547148018+00:00 early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.702518\n[INFO 2023-02-16T06:13:52.915594896+00:00 early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.698683\n[INFO 2023-02-16T06:15:53.022305922+00:00 early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.742294\n[INFO 2023-02-16T06:17:30.307638837+00:00 kernel.cc:905] Export model in log directory: /tmp/tmp85tojlvh with prefix ed87f04dcf6a43ed\n[INFO 2023-02-16T06:17:30.358211124+00:00 kernel.cc:923] Save model in resources\n[INFO 2023-02-16T06:17:30.370142594+00:00 abstract_model.cc:849] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.698145\n\nAccuracy: 0.850134  CI95[W][0 1]\nErrorRate: : 0.149866\n\n\nConfusion Table:\ntruth\\prediction\n   0     1     2\n0  0     0     0\n1  0  3432   406\n2  0   492  1662\nTotal: 5992\n\nOne vs other classes:\n\n[INFO 2023-02-16T06:17:30.407302049+00:00 kernel.cc:1214] Loading model from path /tmp/tmp85tojlvh/model/ with prefix ed87f04dcf6a43ed\n[INFO 2023-02-16T06:17:30.548990651+00:00 decision_forest.cc:661] Model loaded with 296 root(s), 60546 node(s), and 18 input feature(s).\n[INFO 2023-02-16T06:17:30.549043921+00:00 abstract_model.cc:1311] Engine \"GradientBoostedTreesGeneric\" built\n[INFO 2023-02-16T06:17:30.549071021+00:00 kernel.cc:1046] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"Model trained in 0:15:37.530129\nCompiling model...\nModel compiled.\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7faf8c1b3150>"},"metadata":{}}]},{"cell_type":"code","source":"y_preds_tuned = tuned_model.predict(test_ds)[:, 0]","metadata":{"execution":{"iopub.status.busy":"2023-02-16T06:21:03.202191Z","iopub.execute_input":"2023-02-16T06:21:03.202538Z","iopub.status.idle":"2023-02-16T06:21:04.519659Z","shell.execute_reply.started":"2023-02-16T06:21:03.202512Z","shell.execute_reply":"2023-02-16T06:21:04.518620Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"29/29 [==============================] - 1s 43ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"submission = pd.DataFrame({\"id\": test_idx, \"booking_status\": y_preds_tuned})\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-16T06:21:25.223614Z","iopub.execute_input":"2023-02-16T06:21:25.223977Z","iopub.status.idle":"2023-02-16T06:21:25.235941Z","shell.execute_reply.started":"2023-02-16T06:21:25.223949Z","shell.execute_reply":"2023-02-16T06:21:25.234818Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"      id  booking_status\n0  42100        0.064190\n1  42101        0.057226\n2  42102        0.219323\n3  42103        0.062739\n4  42104        0.562021","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>booking_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>42100</td>\n      <td>0.064190</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>42101</td>\n      <td>0.057226</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>42102</td>\n      <td>0.219323</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>42103</td>\n      <td>0.062739</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>42104</td>\n      <td>0.562021</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T06:21:42.267625Z","iopub.execute_input":"2023-02-16T06:21:42.267960Z","iopub.status.idle":"2023-02-16T06:21:42.315313Z","shell.execute_reply.started":"2023-02-16T06:21:42.267933Z","shell.execute_reply":"2023-02-16T06:21:42.314362Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# def cross_validate_with_features_and_hp_template(X, y, X_org, y_org, all_features):\n#     N_FOLDS = 5\n    \n#     skf = StratifiedKFold(n_splits=N_FOLDS, random_state=1337, shuffle=True)\n#     cv_scores = np.zeros(N_FOLDS)\n    \n#     for fold_id, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n        \n#         X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n#         y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n#         # combining with original\n#         X_tr = pd.concat([X_tr, X_org], axis=0)\n#         y_tr = pd.concat([y_tr, y_org], axis=0)\n\n#         X_tr = pd.concat([X_tr, y_tr], axis=1)\n        \n        \n#         X_tr_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_tr, label=\"booking_status\")\n#         X_val_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_val)\n        \n#         model = tfdf.keras.GradientBoostedTreesModel(verbose=0, features=all_features, exclude_non_specified_features=True,\n#                                                     hyperparameter_template=\"benchmark_rank1\")\n#         model.fit(combined_ds)\n        \n#         y_pred = model.predict(X_val_ds)[:, 0]\n        \n#         auc = roc_auc_score(y_val, y_pred)\n        \n#         print(f\"Fold: {fold_id} \\t | \\t auc: {auc}\")\n        \n#         cv_scores[fold_id] = auc\n    \n#     avg_auc = np.mean(cv_scores)\n#     print(f\"AVG AUC: {avg_auc}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing\nTensorflow docs says, it doesn't need preprocessing, so let's see first how well it fares.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X = train.drop(columns=\"booking_status\")\n# y = train.booking_status\n# X_original = original.drop(columns=\"booking_status\")\n# y_original = original.booking_status","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len_X = len(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X[cat_features] = X[cat_features].astype(\"category\")\n# test[cat_features] = test[cat_features].astype(\"category\")\n# X_original[cat_features] = X_original[cat_features].astype(\"category\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_combined = pd.concat([X, X_original], axis=0)\n# y_combined = pd.concat([y, y_original], axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoding Categorical features","metadata":{}},{"cell_type":"code","source":"# loe = LeaveOneOutEncoder(sigma=0.05)\n# loe.fit(X_combined[cat_features], y=y_combined)\n# X_combined[cat_features] = loe.transform(X_combined[cat_features])\n# test[cat_features] = loe.transform(test[cat_features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test[\"no_of_children\"] = test[\"no_of_children\"].astype(\"int\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test[\"no_of_previous_cancellations\"] = test[\"no_of_previous_cancellations\"].astype(\"int\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Normalizing numeriacl features","metadata":{}},{"cell_type":"code","source":"# numerical_features = [\"lead_time\", \"avg_price_per_room\"]\n\n# sc = StandardScaler()\n# sc.fit(X_combined[numerical_features])\n# X_combined[numerical_features] = sc.transform(X_combined[numerical_features])\n# test[numerical_features] = sc.transform(test[numerical_features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Separating datasets","metadata":{}},{"cell_type":"code","source":"# X = X_combined.iloc[:len_X, :]\n# y = y_combined.iloc[:len_X]\n# X_org = X_combined.iloc[len_X: , :]\n# y_org = y_combined.iloc[len_X:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(X), len(X_org), len(y), len(y_org)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing for training\nWe'll only use data points from competition datset for validation since our goal is to get a model that performs best on competition dataset, not original dataset.","metadata":{}},{"cell_type":"code","source":"# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True,\n#                                                  random_state=1337, stratify=y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_preds_final = np.mean([y_preds_xgb, y_preds_lgbm], axis=0)\n# y_preds_final.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = pd.DataFrame({\"id\": test_idx, \"booking_status\": y_preds_final})\n# submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}