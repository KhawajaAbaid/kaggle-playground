{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Notebook Purpose:\n## The main purpose of this notebook is to serve as a guide to train multiple top of the line models and combine their predictions.\n## There will be NO EDA,\n### for that check out this brilliant EDA by SERGEY SAHAROVSKIY here https://www.kaggle.com/code/sergiosaharovskiy/ps-s3e2-2023-eda-and-base-pytorch-model","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom pathlib import Path\nimport xgboost as xgb\nimport lightgbm as lgbm\nimport catboost\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom IPython.display import display\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport optuna\nfrom optuna.samplers import TPESampler\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-10T16:37:43.698768Z","iopub.execute_input":"2023-01-10T16:37:43.699283Z","iopub.status.idle":"2023-01-10T16:37:52.194502Z","shell.execute_reply.started":"2023-01-10T16:37:43.699219Z","shell.execute_reply":"2023-01-10T16:37:52.193352Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:37:58.121381Z","iopub.execute_input":"2023-01-10T16:37:58.121784Z","iopub.status.idle":"2023-01-10T16:37:58.126498Z","shell.execute_reply.started":"2023-01-10T16:37:58.121750Z","shell.execute_reply":"2023-01-10T16:37:58.125322Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"BASE_DIR = Path(\"/kaggle/input/playground-series-s3e2/\")\n\ntrain = pd.read_csv(BASE_DIR / \"train.csv\").drop(columns=\"id\")\ntest = pd.read_csv(BASE_DIR / \"test.csv\").drop(columns=\"id\")","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:37:58.483986Z","iopub.execute_input":"2023-01-10T16:37:58.484409Z","iopub.status.idle":"2023-01-10T16:37:58.575707Z","shell.execute_reply.started":"2023-01-10T16:37:58.484371Z","shell.execute_reply":"2023-01-10T16:37:58.574610Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:37:58.635644Z","iopub.execute_input":"2023-01-10T16:37:58.636223Z","iopub.status.idle":"2023-01-10T16:37:58.657489Z","shell.execute_reply.started":"2023-01-10T16:37:58.636189Z","shell.execute_reply":"2023-01-10T16:37:58.656318Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   gender   age  hypertension  heart_disease ever_married work_type  \\\n0    Male  28.0             0              0          Yes   Private   \n1    Male  33.0             0              0          Yes   Private   \n2  Female  42.0             0              0          Yes   Private   \n3    Male  56.0             0              0          Yes   Private   \n4  Female  24.0             0              0           No   Private   \n\n  Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n0          Urban              79.53  31.1     never smoked       0  \n1          Rural              78.44  23.9  formerly smoked       0  \n2          Rural             103.00  40.3          Unknown       0  \n3          Urban              64.87  28.8     never smoked       0  \n4          Rural              73.36  28.8     never smoked       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>age</th>\n      <th>hypertension</th>\n      <th>heart_disease</th>\n      <th>ever_married</th>\n      <th>work_type</th>\n      <th>Residence_type</th>\n      <th>avg_glucose_level</th>\n      <th>bmi</th>\n      <th>smoking_status</th>\n      <th>stroke</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Male</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>79.53</td>\n      <td>31.1</td>\n      <td>never smoked</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Male</td>\n      <td>33.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>78.44</td>\n      <td>23.9</td>\n      <td>formerly smoked</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Female</td>\n      <td>42.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>103.00</td>\n      <td>40.3</td>\n      <td>Unknown</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Male</td>\n      <td>56.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>64.87</td>\n      <td>28.8</td>\n      <td>never smoked</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Female</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>73.36</td>\n      <td>28.8</td>\n      <td>never smoked</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"### First and foremost we'll check for any missing vales","metadata":{}},{"cell_type":"code","source":"pd.concat([train.isnull().sum().rename(\"missing_values_in_train\"),\n           test.isnull().sum().rename(\"missing_values_in_test\")],\n          axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:37:59.086433Z","iopub.execute_input":"2023-01-10T16:37:59.086879Z","iopub.status.idle":"2023-01-10T16:37:59.109295Z","shell.execute_reply.started":"2023-01-10T16:37:59.086835Z","shell.execute_reply":"2023-01-10T16:37:59.108228Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                   missing_values_in_train  missing_values_in_test\ngender                                   0                     0.0\nage                                      0                     0.0\nhypertension                             0                     0.0\nheart_disease                            0                     0.0\never_married                             0                     0.0\nwork_type                                0                     0.0\nResidence_type                           0                     0.0\navg_glucose_level                        0                     0.0\nbmi                                      0                     0.0\nsmoking_status                           0                     0.0\nstroke                                   0                     NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>missing_values_in_train</th>\n      <th>missing_values_in_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>gender</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>hypertension</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>heart_disease</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ever_married</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>work_type</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Residence_type</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>avg_glucose_level</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>bmi</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>smoking_status</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>stroke</th>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### INSIGHTS: Phew, no missing values to deal with today!","metadata":{}},{"cell_type":"markdown","source":"### BEFORE continuing on with our preprocessing it's a good idea to combile both train and test datasets and them do preprocessing like encoding and stuff","metadata":{}},{"cell_type":"code","source":"df = pd.concat([train.drop(columns=[\"stroke\"]), test], axis=0).reset_index(drop=True)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:37:59.509409Z","iopub.execute_input":"2023-01-10T16:37:59.510156Z","iopub.status.idle":"2023-01-10T16:37:59.550348Z","shell.execute_reply.started":"2023-01-10T16:37:59.510111Z","shell.execute_reply":"2023-01-10T16:37:59.549182Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"       gender   age  hypertension  heart_disease ever_married work_type  \\\n0        Male  28.0             0              0          Yes   Private   \n1        Male  33.0             0              0          Yes   Private   \n2      Female  42.0             0              0          Yes   Private   \n3        Male  56.0             0              0          Yes   Private   \n4      Female  24.0             0              0           No   Private   \n...       ...   ...           ...            ...          ...       ...   \n25503  Female  27.0             0              0           No   Private   \n25504    Male  49.0             0              0          Yes   Private   \n25505  Female   3.0             0              0           No  children   \n25506    Male  31.0             0              0          Yes   Private   \n25507  Female   2.0             0              0           No  children   \n\n      Residence_type  avg_glucose_level   bmi   smoking_status  \n0              Urban              79.53  31.1     never smoked  \n1              Rural              78.44  23.9  formerly smoked  \n2              Rural             103.00  40.3          Unknown  \n3              Urban              64.87  28.8     never smoked  \n4              Rural              73.36  28.8     never smoked  \n...              ...                ...   ...              ...  \n25503          Urban              75.77  17.6     never smoked  \n25504          Urban             102.91  26.7          Unknown  \n25505          Rural             104.04  18.3          Unknown  \n25506          Urban              82.41  28.7     never smoked  \n25507          Urban              85.12  14.8          Unknown  \n\n[25508 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>age</th>\n      <th>hypertension</th>\n      <th>heart_disease</th>\n      <th>ever_married</th>\n      <th>work_type</th>\n      <th>Residence_type</th>\n      <th>avg_glucose_level</th>\n      <th>bmi</th>\n      <th>smoking_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Male</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>79.53</td>\n      <td>31.1</td>\n      <td>never smoked</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Male</td>\n      <td>33.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>78.44</td>\n      <td>23.9</td>\n      <td>formerly smoked</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Female</td>\n      <td>42.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>103.00</td>\n      <td>40.3</td>\n      <td>Unknown</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Male</td>\n      <td>56.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>64.87</td>\n      <td>28.8</td>\n      <td>never smoked</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Female</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>73.36</td>\n      <td>28.8</td>\n      <td>never smoked</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25503</th>\n      <td>Female</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>75.77</td>\n      <td>17.6</td>\n      <td>never smoked</td>\n    </tr>\n    <tr>\n      <th>25504</th>\n      <td>Male</td>\n      <td>49.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>102.91</td>\n      <td>26.7</td>\n      <td>Unknown</td>\n    </tr>\n    <tr>\n      <th>25505</th>\n      <td>Female</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>children</td>\n      <td>Rural</td>\n      <td>104.04</td>\n      <td>18.3</td>\n      <td>Unknown</td>\n    </tr>\n    <tr>\n      <th>25506</th>\n      <td>Male</td>\n      <td>31.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>82.41</td>\n      <td>28.7</td>\n      <td>never smoked</td>\n    </tr>\n    <tr>\n      <th>25507</th>\n      <td>Female</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>children</td>\n      <td>Urban</td>\n      <td>85.12</td>\n      <td>14.8</td>\n      <td>Unknown</td>\n    </tr>\n  </tbody>\n</table>\n<p>25508 rows × 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Identifying Categorical Features","metadata":{}},{"cell_type":"code","source":"pd.concat([df.nunique().rename(\"Unique Values\"), df.dtypes.rename(\"Data Type\")], axis=1).sort_values(by=\"Unique Values\")","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:37:59.781874Z","iopub.execute_input":"2023-01-10T16:37:59.782342Z","iopub.status.idle":"2023-01-10T16:37:59.812761Z","shell.execute_reply.started":"2023-01-10T16:37:59.782261Z","shell.execute_reply":"2023-01-10T16:37:59.811515Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                   Unique Values Data Type\nhypertension                   2     int64\nheart_disease                  2     int64\never_married                   2    object\nResidence_type                 2    object\ngender                         3    object\nsmoking_status                 4    object\nwork_type                      5    object\nage                          109   float64\nbmi                          441   float64\navg_glucose_level           4345   float64","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unique Values</th>\n      <th>Data Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>hypertension</th>\n      <td>2</td>\n      <td>int64</td>\n    </tr>\n    <tr>\n      <th>heart_disease</th>\n      <td>2</td>\n      <td>int64</td>\n    </tr>\n    <tr>\n      <th>ever_married</th>\n      <td>2</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>Residence_type</th>\n      <td>2</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>gender</th>\n      <td>3</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>smoking_status</th>\n      <td>4</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>work_type</th>\n      <td>5</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>109</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>bmi</th>\n      <td>441</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>avg_glucose_level</th>\n      <td>4345</td>\n      <td>float64</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### INSIGHTS: \n##### As we can see, most of the columns/features are categorical - in that they contain at most 2, 3 or 5 unique values.\n##### And importantly, except for the hypertension and heart_disease columns, every other categorical column is of object/string type. And the reason for that is that both of these columns are already binary/one hot encoded as they contain either 0 or 1, indicating presence or absence of feature\n#### So, we will NOT one hot encode hypertension and heart_disease cols, but will do the rest!","metadata":{}},{"cell_type":"code","source":"cat_cols = [col for col in df.columns if df[col].nunique() <= 5]\ncat_cols","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:00.132668Z","iopub.execute_input":"2023-01-10T16:38:00.133050Z","iopub.status.idle":"2023-01-10T16:38:00.153710Z","shell.execute_reply.started":"2023-01-10T16:38:00.133018Z","shell.execute_reply":"2023-01-10T16:38:00.152630Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['gender',\n 'hypertension',\n 'heart_disease',\n 'ever_married',\n 'work_type',\n 'Residence_type',\n 'smoking_status']"},"metadata":{}}]},{"cell_type":"code","source":"# lets exclude hypertension and heart_disease as they are already encoded\ncols_to_encode = list(set(cat_cols) - set(['hypertension', 'heart_disease']))\ncols_to_encode","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:00.313737Z","iopub.execute_input":"2023-01-10T16:38:00.314102Z","iopub.status.idle":"2023-01-10T16:38:00.321441Z","shell.execute_reply.started":"2023-01-10T16:38:00.314071Z","shell.execute_reply":"2023-01-10T16:38:00.320379Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['gender', 'Residence_type', 'smoking_status', 'work_type', 'ever_married']"},"metadata":{}}]},{"cell_type":"markdown","source":"### Encoding Categorical Features\n#### Since this data contains categorical features/columns, so our main preprocessing will concern with encoding them\n#### Now, we could do this in two ways, either One Hot Encoding or Label/Oridinal Encoding\n#### Here we will One Hote Encode but feel free to experiment with other techniques","metadata":{}},{"cell_type":"code","source":"# intialize the one hot encoder\none_hot_enc = OneHotEncoder(dtype=\"int64\")\n\n# fit it to the features we're interested in\none_hot_enc.fit(df[cols_to_encode])\n\n# transform the features/columns and store the new columns back in the original dataset\n# by default, the one_hot_enc.transform method returns a sparse matrix which we convert into numpy ndarray \n# and we use encoder's get features_names_out method passing it the cols we encoded to get the output features names for them. (i hope that made sense :p)\n# see the cell next to see what I'm talking about\ndf[one_hot_enc.get_feature_names_out(cols_to_encode)] = pd.DataFrame(one_hot_enc.transform(df[cols_to_encode]).toarray())\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:00.661019Z","iopub.execute_input":"2023-01-10T16:38:00.661710Z","iopub.status.idle":"2023-01-10T16:38:00.748472Z","shell.execute_reply.started":"2023-01-10T16:38:00.661664Z","shell.execute_reply":"2023-01-10T16:38:00.747325Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   gender   age  hypertension  heart_disease ever_married work_type  \\\n0    Male  28.0             0              0          Yes   Private   \n1    Male  33.0             0              0          Yes   Private   \n2  Female  42.0             0              0          Yes   Private   \n3    Male  56.0             0              0          Yes   Private   \n4  Female  24.0             0              0           No   Private   \n\n  Residence_type  avg_glucose_level   bmi   smoking_status  ...  \\\n0          Urban              79.53  31.1     never smoked  ...   \n1          Rural              78.44  23.9  formerly smoked  ...   \n2          Rural             103.00  40.3          Unknown  ...   \n3          Urban              64.87  28.8     never smoked  ...   \n4          Rural              73.36  28.8     never smoked  ...   \n\n   smoking_status_formerly smoked  smoking_status_never smoked  \\\n0                               0                            1   \n1                               1                            0   \n2                               0                            0   \n3                               0                            1   \n4                               0                            1   \n\n   smoking_status_smokes  work_type_Govt_job  work_type_Never_worked  \\\n0                      0                   0                       0   \n1                      0                   0                       0   \n2                      0                   0                       0   \n3                      0                   0                       0   \n4                      0                   0                       0   \n\n   work_type_Private  work_type_Self-employed  work_type_children  \\\n0                  1                        0                   0   \n1                  1                        0                   0   \n2                  1                        0                   0   \n3                  1                        0                   0   \n4                  1                        0                   0   \n\n   ever_married_No  ever_married_Yes  \n0                0                 1  \n1                0                 1  \n2                0                 1  \n3                0                 1  \n4                1                 0  \n\n[5 rows x 26 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>age</th>\n      <th>hypertension</th>\n      <th>heart_disease</th>\n      <th>ever_married</th>\n      <th>work_type</th>\n      <th>Residence_type</th>\n      <th>avg_glucose_level</th>\n      <th>bmi</th>\n      <th>smoking_status</th>\n      <th>...</th>\n      <th>smoking_status_formerly smoked</th>\n      <th>smoking_status_never smoked</th>\n      <th>smoking_status_smokes</th>\n      <th>work_type_Govt_job</th>\n      <th>work_type_Never_worked</th>\n      <th>work_type_Private</th>\n      <th>work_type_Self-employed</th>\n      <th>work_type_children</th>\n      <th>ever_married_No</th>\n      <th>ever_married_Yes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Male</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>79.53</td>\n      <td>31.1</td>\n      <td>never smoked</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Male</td>\n      <td>33.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>78.44</td>\n      <td>23.9</td>\n      <td>formerly smoked</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Female</td>\n      <td>42.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>103.00</td>\n      <td>40.3</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Male</td>\n      <td>56.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Private</td>\n      <td>Urban</td>\n      <td>64.87</td>\n      <td>28.8</td>\n      <td>never smoked</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Female</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>Private</td>\n      <td>Rural</td>\n      <td>73.36</td>\n      <td>28.8</td>\n      <td>never smoked</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# here's what this returns - the names of new cols/features that it automatically inferred based on the values in categorical cols that we wanted to encode\none_hot_enc.get_feature_names_out(cols_to_encode)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:00.755960Z","iopub.execute_input":"2023-01-10T16:38:00.756386Z","iopub.status.idle":"2023-01-10T16:38:00.764380Z","shell.execute_reply.started":"2023-01-10T16:38:00.756351Z","shell.execute_reply":"2023-01-10T16:38:00.763500Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array(['gender_Female', 'gender_Male', 'gender_Other',\n       'Residence_type_Rural', 'Residence_type_Urban',\n       'smoking_status_Unknown', 'smoking_status_formerly smoked',\n       'smoking_status_never smoked', 'smoking_status_smokes',\n       'work_type_Govt_job', 'work_type_Never_worked',\n       'work_type_Private', 'work_type_Self-employed',\n       'work_type_children', 'ever_married_No', 'ever_married_Yes'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Let's drop the original categorical columns that now have been encoded","metadata":{}},{"cell_type":"code","source":"df.drop(columns=cols_to_encode, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:01.104265Z","iopub.execute_input":"2023-01-10T16:38:01.104658Z","iopub.status.idle":"2023-01-10T16:38:01.120448Z","shell.execute_reply.started":"2023-01-10T16:38:01.104627Z","shell.execute_reply":"2023-01-10T16:38:01.119064Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# sanity check that the cols were dropped :D\nlen(df.columns)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:01.250943Z","iopub.execute_input":"2023-01-10T16:38:01.251354Z","iopub.status.idle":"2023-01-10T16:38:01.257576Z","shell.execute_reply.started":"2023-01-10T16:38:01.251320Z","shell.execute_reply":"2023-01-10T16:38:01.256547Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"21"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Let's separate the train data from test data before we move on to the modeling phase","metadata":{}},{"cell_type":"code","source":"X = df.iloc[:-len(test), :]\n\ntest_new = df.iloc[-len(test):, :]\n\n# the unprocessed and raw train dataframe that we loaded earlier\ny = train.stroke","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:01.626160Z","iopub.execute_input":"2023-01-10T16:38:01.627279Z","iopub.status.idle":"2023-01-10T16:38:01.634735Z","shell.execute_reply.started":"2023-01-10T16:38:01.627210Z","shell.execute_reply":"2023-01-10T16:38:01.633387Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# sanity check\nlen(X) == len(train)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:01.777864Z","iopub.execute_input":"2023-01-10T16:38:01.778288Z","iopub.status.idle":"2023-01-10T16:38:01.786107Z","shell.execute_reply.started":"2023-01-10T16:38:01.778254Z","shell.execute_reply":"2023-01-10T16:38:01.784860Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# Modeling","metadata":{"execution":{"iopub.status.busy":"2023-01-10T14:48:21.617424Z","iopub.execute_input":"2023-01-10T14:48:21.617829Z","iopub.status.idle":"2023-01-10T14:48:21.625013Z","shell.execute_reply.started":"2023-01-10T14:48:21.617795Z","shell.execute_reply":"2023-01-10T14:48:21.623932Z"}}},{"cell_type":"markdown","source":"## Setting up Cross Validation\n### Before we model, it's a good idea to define a cross validation function to cross validate our models","metadata":{}},{"cell_type":"code","source":"def cross_validate(X, y, model):\n    kf = KFold(n_splits=5, shuffle=True, random_state=1337) # thumbs up if you're 1337 gang :D jk\n    \n    cv_scores = []\n    \n    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n                \n        # training\n        model.fit(X_train, y_train, verbose=0)\n\n        # predicting\n        y_pred = model.predict_proba(X_val)[:, 1]\n        \n        auc = roc_auc_score(y_val, y_pred)\n        \n        print(f\"Fold: {fold} \\t auc: {auc}\")\n        \n        cv_scores.append(auc)\n    \n    avg_auc = np.mean(cv_scores)\n    print(f\"Avg AUC: {avg_auc}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:02.517523Z","iopub.execute_input":"2023-01-10T16:38:02.518023Z","iopub.status.idle":"2023-01-10T16:38:02.528891Z","shell.execute_reply.started":"2023-01-10T16:38:02.517981Z","shell.execute_reply":"2023-01-10T16:38:02.527810Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost","metadata":{}},{"cell_type":"code","source":"# randomly chosen parameters for now - make sure to tune your hyperparameters as they provide a significant boost!\nxgb_params = {'n_estimators': 456,\n 'max_depth': 8,\n 'learning_rate': 0.0268,\n 'min_child_weight': 10,\n 'gamma': 0.22,\n 'subsample': 0.62,\n 'colsample_bytree': 0.33,\n 'reg_alpha': 1.5211300201400934e-05,\n 'reg_lambda': 0.0005497911242012908}","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:02.889443Z","iopub.execute_input":"2023-01-10T16:38:02.890350Z","iopub.status.idle":"2023-01-10T16:38:02.897856Z","shell.execute_reply.started":"2023-01-10T16:38:02.890312Z","shell.execute_reply":"2023-01-10T16:38:02.896814Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"xgb_model = xgb.XGBClassifier(**xgb_params)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:03.075275Z","iopub.execute_input":"2023-01-10T16:38:03.075657Z","iopub.status.idle":"2023-01-10T16:38:03.081226Z","shell.execute_reply.started":"2023-01-10T16:38:03.075625Z","shell.execute_reply":"2023-01-10T16:38:03.080155Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"cross_validate(X, y, xgb_model)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:03.262682Z","iopub.execute_input":"2023-01-10T16:38:03.263095Z","iopub.status.idle":"2023-01-10T16:38:20.857760Z","shell.execute_reply.started":"2023-01-10T16:38:03.263060Z","shell.execute_reply":"2023-01-10T16:38:20.856847Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Fold: 0 \t auc: 0.8886450204384986\nFold: 1 \t auc: 0.8719419115163795\nFold: 2 \t auc: 0.8828447182641516\nFold: 3 \t auc: 0.88107944081701\nFold: 4 \t auc: 0.8832801318875352\nAvg AUC: 0.8815582445847149\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## LightGBM","metadata":{}},{"cell_type":"code","source":"# randomly chosen params - make sure to tune yours!\nlgbm_params = {'n_estimators': 10000,\n                 'num_rounds': 291,\n                 'learning_rate': 0.14293898453640025,\n                 'num_leaves': 2780,\n                 'max_depth': 8,\n                 'min_data_in_leaf': 400,\n                 'lambda_l1': 45,\n                 'lambda_l2': 0,\n                 'min_gain_to_split': 0.002584545158305085,\n                 'bagging_fraction': 0.9,\n                 'bagging_freq': 1,\n                 'feature_fraction': 0.4}","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:20.859351Z","iopub.execute_input":"2023-01-10T16:38:20.859920Z","iopub.status.idle":"2023-01-10T16:38:20.865762Z","shell.execute_reply.started":"2023-01-10T16:38:20.859885Z","shell.execute_reply":"2023-01-10T16:38:20.864432Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"lgbm_model = lgbm.LGBMClassifier(**lgbm_params)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:20.867152Z","iopub.execute_input":"2023-01-10T16:38:20.868018Z","iopub.status.idle":"2023-01-10T16:38:20.913310Z","shell.execute_reply.started":"2023-01-10T16:38:20.867985Z","shell.execute_reply":"2023-01-10T16:38:20.911975Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"cross_validate(X, y, lgbm_model)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:20.916479Z","iopub.execute_input":"2023-01-10T16:38:20.917431Z","iopub.status.idle":"2023-01-10T16:38:21.877809Z","shell.execute_reply.started":"2023-01-10T16:38:20.917371Z","shell.execute_reply":"2023-01-10T16:38:21.876794Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\nFold: 0 \t auc: 0.8893025942958009\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\nFold: 1 \t auc: 0.8625818980074299\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\nFold: 2 \t auc: 0.8905009635835321\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\nFold: 3 \t auc: 0.872217687929014\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\nFold: 4 \t auc: 0.8810129395125086\nAvg AUC: 0.8791232166656572\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## CatBoost","metadata":{}},{"cell_type":"code","source":"# randomly chosen params - make sure to tune yours!\ncatboost_params = {'loss_function': 'Logloss',\n                     'learning_rate': 0.065,\n                     'l2_leaf_reg': 0.43,\n                     'colsample_bylevel': 0.083,\n                     'depth': 5,\n                     'min_data_in_leaf': 15,\n                     'subsample': 0.73}","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:21.881698Z","iopub.execute_input":"2023-01-10T16:38:21.882592Z","iopub.status.idle":"2023-01-10T16:38:21.888034Z","shell.execute_reply.started":"2023-01-10T16:38:21.882546Z","shell.execute_reply":"2023-01-10T16:38:21.887221Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"catboost_model = catboost.CatBoostClassifier(**catboost_params)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:21.889544Z","iopub.execute_input":"2023-01-10T16:38:21.890228Z","iopub.status.idle":"2023-01-10T16:38:21.903423Z","shell.execute_reply.started":"2023-01-10T16:38:21.890186Z","shell.execute_reply":"2023-01-10T16:38:21.902288Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"cross_validate(X, y, catboost_model)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:38:21.905379Z","iopub.execute_input":"2023-01-10T16:38:21.906110Z","iopub.status.idle":"2023-01-10T16:38:36.074115Z","shell.execute_reply.started":"2023-01-10T16:38:21.906066Z","shell.execute_reply":"2023-01-10T16:38:36.073084Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Fold: 0 \t auc: 0.8846110298216276\nFold: 1 \t auc: 0.8562478892266125\nFold: 2 \t auc: 0.882784806334688\nFold: 3 \t auc: 0.8656454043194373\nFold: 4 \t auc: 0.8598034299167295\nAvg AUC: 0.869818511923819\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Ensembling","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    \"\"\"Finding best weighted average params using optuna :D idea by: Khawaja Abaid (me) \"\"\"\n    w_xgb = round(trial.suggest_discrete_uniform(\"w_xgb\", 0.0, 1.0, 0.1),1)\n    w_lgbm = round(trial.suggest_discrete_uniform(\"w_lgbm\", 0.0, float(round(1.0 - w_xgb, 1)), 0.1),1)\n    w_cat = 1.0 - w_xgb - w_lgbm\n    \n    print(f\"sum is {sum([w_xgb, w_lgbm, w_cat])}\")\n    \n    if sum([w_xgb, w_lgbm, w_cat]) == 1.0:\n    \n        cv = KFold(n_splits=5, shuffle=True, random_state=1337)\n\n        cv_scores = np.empty(5)\n        for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n            y_train, y_test = y[train_idx], y[test_idx]\n\n            xgb_model = xgb.XGBClassifier(**xgb_params)\n            xgb_model.fit(X_train, y_train, verbose=0)\n            y_preds_xgb = xgb_model.predict_proba(X_test)[:, 1]\n\n            lgbm_model = lgbm.LGBMClassifier(**lgbm_params)\n            lgbm_model.fit(X_train, y_train, verbose=0)\n            y_preds_lgbm = lgbm_model.predict_proba(X_test)[:, 1]\n\n            catboost_model = catboost.CatBoostClassifier(**catboost_params)\n            catboost_model.fit(X_train, y_train, verbose=0)\n            y_preds_cat = catboost_model.predict_proba(X_test)[:, 1]\n\n            y_preds_final = y_preds_xgb * w_xgb + y_preds_lgbm * w_lgbm + y_preds_cat * w_cat\n\n            auc = roc_auc_score(y_test, y_preds_final)\n\n            cv_scores[idx] = auc\n        \n        avg_auc = np.mean(cv_scores)\n    \n    # else if sum is not equal to 1.0, skip and for that we'll just reutn -99 as it will be the smallest value\n    else:\n        avg_auc = -99\n    \n    return avg_auc","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:54:16.077019Z","iopub.execute_input":"2023-01-10T16:54:16.077975Z","iopub.status.idle":"2023-01-10T16:54:16.090432Z","shell.execute_reply.started":"2023-01-10T16:54:16.077930Z","shell.execute_reply":"2023-01-10T16:54:16.089487Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(study_name=\"weights\", direction=\"maximize\")\nstudy.optimize(objective, n_trials=10)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:54:17.933946Z","iopub.execute_input":"2023-01-10T16:54:17.934397Z","iopub.status.idle":"2023-01-10T16:59:42.913048Z","shell.execute_reply.started":"2023-01-10T16:54:17.934358Z","shell.execute_reply":"2023-01-10T16:59:42.911893Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2023-01-10 16:54:17,935]\u001b[0m A new study created in memory with name: weights\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"sum is 1.0\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2023-01-10 16:54:50,326]\u001b[0m Trial 0 finished with value: 0.8824936248197561 and parameters: {'w_xgb': 0.9, 'w_lgbm': 0.0}. Best is trial 0 with value: 0.8824936248197561.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"sum is 1.0\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2023-01-10 16:55:22,373]\u001b[0m Trial 1 finished with value: 0.8834245785414824 and parameters: {'w_xgb': 0.1, 'w_lgbm': 0.6000000000000001}. Best is trial 1 with value: 0.8834245785414824.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"sum is 1.0\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2023-01-10 16:55:54,534]\u001b[0m Trial 2 finished with value: 0.8836082302164648 and parameters: {'w_xgb': 0.8, 'w_lgbm': 0.1}. Best is trial 2 with value: 0.8836082302164648.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"sum is 1.0\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2023-01-10 16:56:26,414]\u001b[0m Trial 3 finished with value: 0.8831721755348235 and parameters: {'w_xgb': 0.30000000000000004, 'w_lgbm': 0.2}. Best is trial 2 with value: 0.8836082302164648.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"sum is 1.0\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2023-01-10 16:56:58,520]\u001b[0m Trial 4 finished with value: 0.8827474282627332 and parameters: {'w_xgb': 0.9, 'w_lgbm': 0.1}. Best is trial 2 with value: 0.8836082302164648.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"sum is 1.0\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2023-01-10 16:57:31,538]\u001b[0m Trial 5 finished with value: 0.8846031167809967 and parameters: {'w_xgb': 0.6000000000000001, 'w_lgbm': 0.2}. Best is trial 5 with value: 0.8846031167809967.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"sum is 1.0\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2023-01-10 16:58:04,918]\u001b[0m Trial 6 finished with value: 0.8815582445847149 and parameters: {'w_xgb': 1.0, 'w_lgbm': 0.0}. Best is trial 5 with value: 0.8846031167809967.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"sum is 1.0\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2023-01-10 16:58:38,069]\u001b[0m Trial 7 finished with value: 0.8815582445847149 and parameters: {'w_xgb': 1.0, 'w_lgbm': 0.0}. Best is trial 5 with value: 0.8846031167809967.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"sum is 1.0\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2023-01-10 16:59:10,831]\u001b[0m Trial 8 finished with value: 0.8836082302164648 and parameters: {'w_xgb': 0.8, 'w_lgbm': 0.1}. Best is trial 5 with value: 0.8846031167809967.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"sum is 1.0\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n[LightGBM] [Warning] num_iterations is set=291, num_rounds=291 will be ignored. Current value: num_iterations=291\n[LightGBM] [Warning] min_gain_to_split is set=0.002584545158305085, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.002584545158305085\n[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2023-01-10 16:59:42,908]\u001b[0m Trial 9 finished with value: 0.8811756329240407 and parameters: {'w_xgb': 0.0, 'w_lgbm': 0.5}. Best is trial 5 with value: 0.8846031167809967.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"study.best_value","metadata":{"execution":{"iopub.status.busy":"2023-01-10T17:01:01.105843Z","iopub.execute_input":"2023-01-10T17:01:01.106537Z","iopub.status.idle":"2023-01-10T17:01:01.115430Z","shell.execute_reply.started":"2023-01-10T17:01:01.106496Z","shell.execute_reply":"2023-01-10T17:01:01.114176Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"0.8846031167809967"},"metadata":{}}]},{"cell_type":"code","source":"study.best_params","metadata":{"execution":{"iopub.status.busy":"2023-01-10T17:01:08.778686Z","iopub.execute_input":"2023-01-10T17:01:08.779106Z","iopub.status.idle":"2023-01-10T17:01:08.786495Z","shell.execute_reply.started":"2023-01-10T17:01:08.779069Z","shell.execute_reply":"2023-01-10T17:01:08.785268Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"{'w_xgb': 0.6000000000000001, 'w_lgbm': 0.2}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Keras","metadata":{}},{"cell_type":"code","source":"# we'll work with keras some other day","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:37:37.394261Z","iopub.execute_input":"2023-01-10T16:37:37.395118Z","iopub.status.idle":"2023-01-10T16:37:37.413843Z","shell.execute_reply.started":"2023-01-10T16:37:37.395021Z","shell.execute_reply":"2023-01-10T16:37:37.412962Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# inputs = layers.Input(shape=X.shape[1])\n\n# x = layers.Dense(1024, activation=\"relu\")(inputs)\n# x = layers.BatchNormalization()(x)\n# x = layers.Dropout(0.3)(x)\n\n# x = layers.Dense(512, activation=\"relu\")(x)\n# x = layers.BatchNormalization()(x)\n# x = layers.Dropout(0.3)(x)\n\n# x = layers.Dense(256, activation=\"relu\")(x)\n# x = layers.BatchNormalization()(x)\n# x = layers.Dropout(0.3)(x)\n\n# x = layers.Dense(128, activation=\"relu\")(x)\n# x = layers.BatchNormalization()(x)\n# x = layers.Dropout(0.3)(x)\n\n# outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n\n# keras_model = keras.Model(inputs=inputs, outputs=outputs)\n# keras_model.compile(optimizer=\"rmsprop\",\n#                    loss=keras.losses.binary_crossentropy,\n#                    metrics=[keras.metrics.AUC()])","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:34:44.615900Z","iopub.execute_input":"2023-01-10T16:34:44.616372Z","iopub.status.idle":"2023-01-10T16:34:44.775179Z","shell.execute_reply.started":"2023-01-10T16:34:44.616336Z","shell.execute_reply":"2023-01-10T16:34:44.773803Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# early_stopping = keras.callbacks.EarlyStopping(\n#                 patience=20,\n#                 min_delta=0.001,\n#                 monitor=\"val_auc\",\n#                 restore_best_weights=True,\n#                 )","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:34:46.103512Z","iopub.execute_input":"2023-01-10T16:34:46.104000Z","iopub.status.idle":"2023-01-10T16:34:46.109994Z","shell.execute_reply.started":"2023-01-10T16:34:46.103964Z","shell.execute_reply":"2023-01-10T16:34:46.108985Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# sc = StandardScaler()\n# X_scaled = sc.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:34:50.418956Z","iopub.execute_input":"2023-01-10T16:34:50.419358Z","iopub.status.idle":"2023-01-10T16:34:50.437839Z","shell.execute_reply.started":"2023-01-10T16:34:50.419329Z","shell.execute_reply":"2023-01-10T16:34:50.436524Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# def keras_cv(X, y, model):\n#     kf = KFold(n_splits=5, shuffle=True, random_state=1337) # thumbs up if you're 1337 gang :D jk\n    \n#     cv_scores = []\n    \n#     for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n#         X_train, X_val = X[train_idx], X[val_idx]\n#         y_train, y_val = y[train_idx], y[val_idx]\n        \n#         history = model.fit(\n#             X_train, y_train,\n#             validation_data=(X_val, y_val),\n#             batch_size=512,\n#             epochs=50,\n#             callbacks=[early_stopping],\n#             )\n\n#         y_pred = model.predict(X_val)\n        \n#         auc = roc_auc_score(y_val, y_pred)\n        \n#         print(f\"Fold: {fold} \\t auc: {auc}\")\n        \n#         cv_scores.append(auc)\n    \n#     avg_auc = np.mean(cv_scores)\n#     print(f\"Avg AUC: {avg_auc}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:34:54.823419Z","iopub.execute_input":"2023-01-10T16:34:54.824917Z","iopub.status.idle":"2023-01-10T16:34:54.835876Z","shell.execute_reply.started":"2023-01-10T16:34:54.824836Z","shell.execute_reply":"2023-01-10T16:34:54.834082Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# keras_cv(X_scaled, y, keras_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}